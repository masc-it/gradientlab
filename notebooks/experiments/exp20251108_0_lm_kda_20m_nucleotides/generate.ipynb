{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must have gradientlab installed locally - see README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mascit/data/Projects/python/gradientlab/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from gradientlab.data_utils.experiment_path import get_ckpt_path_by_exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'exp20251108_0_lm_kda_20m_nucleotides'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = Path(\".\").resolve().absolute().name\n",
    "ckpt_path = get_ckpt_path_by_exp_name(exp_name)\n",
    "exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = AutoModelForCausalLM.from_pretrained(ckpt_path, trust_remote_code=True).to(device).eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[259,  68,  87,  68,  87,  87,  87,  87,  87,  70,  74,  74,  87,  74,\n",
       "           87,  87,  87,  87,  87,  87,  87,  68,  68,  68,  68,  87,  70,  70,\n",
       "           68,  74,  68,  68,  68,  68,  74,  74,  87, 260]], device='cuda:0'),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer([\"<|im_start|>ATATTTTTCGGTGTTTTTTTAAAATCCAGAAAAGGT<|im_end|>\"], return_tensors=\"pt\", add_special_tokens=False, return_attention_mask=True)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|> ATATTTTTCGGTGTTTTTTTAAAATCCAGAAAAGGTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = model.generate(**inputs, do_sample=False,  max_length=200)\n",
    "tokenizer.decode(ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=None, logits=tensor([[[-22.0882, -22.0852, -22.0902,  ..., -22.0874, -22.1016, -22.0841],\n",
       "         [-21.0337, -21.0265, -21.0262,  ..., -21.0267, -21.0379, -21.0237],\n",
       "         [-22.3566, -22.3536, -22.3558,  ..., -22.3519, -22.3639, -22.3436],\n",
       "         ...,\n",
       "         [-22.5724, -22.5634, -22.5766,  ..., -22.5760, -22.5835, -22.5698],\n",
       "         [-22.0537, -22.0524, -22.0619,  ..., -22.0601, -22.0706, -22.0514],\n",
       "         [-21.9520, -21.9441, -21.9504,  ..., -21.9503, -21.9613, -21.9423]]],\n",
       "       device='cuda:0'), past_key_values=DynamicCache(layers=[]), hidden_states=tensor([[[ 0.0047,  0.0070, -0.0733,  ...,  0.0462, -0.0428,  0.0397],\n",
       "         [-0.0049, -0.0281, -0.0246,  ..., -0.0075, -0.0046,  0.0082],\n",
       "         [-0.0221, -0.0118, -0.0187,  ...,  0.0194, -0.0296,  0.0095],\n",
       "         ...,\n",
       "         [ 0.0273, -0.0283, -0.0367,  ..., -0.0398,  0.0077, -0.0160],\n",
       "         [ 0.0530, -0.0104, -0.0614,  ..., -0.0182,  0.0239, -0.0276],\n",
       "         [ 0.0178, -0.0037, -0.0344,  ..., -0.0053,  0.0149, -0.0014]]],\n",
       "       device='cuda:0'), attentions=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "with torch.inference_mode():\n",
    "    out = model(**inputs)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12032"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "ds_orig = load_from_disk(\"/media/mascit/datasets/nucleotides_std\")\n",
    "\n",
    "ds = ds_orig[\"train\"].to_list() + ds_orig[\"test\"].to_list()\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence_orig': 'ACGGCAGCTCGCCATCATCG',\n",
       "  'sequence': 'ACGGCAGCTCGCCATCATCGGGG',\n",
       "  'label': 0.3,\n",
       "  'task': 'BE39:MELJUSO:zscore'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 752/752 [00:27<00:00, 27.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "features = []\n",
    "\n",
    "for i in tqdm(range(0, len(ds), batch_size)):\n",
    "    batch = ds[i:i+batch_size]\n",
    "    seqs = [el[\"sequence\"] for el in batch]\n",
    "    inputs = tokenizer([f\"<|im_start|>{s}<|im_end|>\" for s in seqs], return_tensors=\"pt\", add_special_tokens=False, return_attention_mask=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.inference_mode():\n",
    "        out = model(**inputs)\n",
    "\n",
    "    batch_features = out.hidden_states[:, -1].tolist()\n",
    "    features.extend(batch_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds = []\n",
    "for item, feature in zip(ds, features):\n",
    "    new_item = {\n",
    "        **item,\n",
    "        **{f\"gpt_{i}\": f for i, f in enumerate(feature)}\n",
    "    }\n",
    "    new_ds.append(new_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence_orig': 'ACGGCAGCTCGCCATCATCG',\n",
       "  'sequence': 'ACGGCAGCTCGCCATCATCGGGG',\n",
       "  'label': 0.3,\n",
       "  'task': 'BE39:MELJUSO:zscore',\n",
       "  'gpt_0': 0.12591403722763062,\n",
       "  'gpt_1': 0.05160713195800781,\n",
       "  'gpt_2': -0.04755336791276932,\n",
       "  'gpt_3': -0.022943109273910522,\n",
       "  'gpt_4': 0.016562532633543015,\n",
       "  'gpt_5': -0.041670870035886765,\n",
       "  'gpt_6': 0.02335725724697113,\n",
       "  'gpt_7': 0.044481560587882996,\n",
       "  'gpt_8': 0.11102955043315887,\n",
       "  'gpt_9': 0.04455827921628952,\n",
       "  'gpt_10': -0.06787913292646408,\n",
       "  'gpt_11': 0.07132302224636078,\n",
       "  'gpt_12': -0.03504953533411026,\n",
       "  'gpt_13': -0.03392065316438675,\n",
       "  'gpt_14': -0.0019646529108285904,\n",
       "  'gpt_15': -0.020946519449353218,\n",
       "  'gpt_16': 0.05419322848320007,\n",
       "  'gpt_17': -0.049541175365448,\n",
       "  'gpt_18': -0.01410716027021408,\n",
       "  'gpt_19': -0.02453221008181572,\n",
       "  'gpt_20': 0.062198225408792496,\n",
       "  'gpt_21': -0.07528197020292282,\n",
       "  'gpt_22': 0.059594471007585526,\n",
       "  'gpt_23': 0.05839304253458977,\n",
       "  'gpt_24': 0.0792023241519928,\n",
       "  'gpt_25': -0.022146280854940414,\n",
       "  'gpt_26': 0.04081190377473831,\n",
       "  'gpt_27': -0.10001568496227264,\n",
       "  'gpt_28': -0.09709024429321289,\n",
       "  'gpt_29': 0.029079236090183258,\n",
       "  'gpt_30': 0.00871620886027813,\n",
       "  'gpt_31': 0.02933201752603054,\n",
       "  'gpt_32': 0.06102992966771126,\n",
       "  'gpt_33': 0.08909466862678528,\n",
       "  'gpt_34': 0.020948970690369606,\n",
       "  'gpt_35': -0.1325227916240692,\n",
       "  'gpt_36': 0.05159919708967209,\n",
       "  'gpt_37': 0.012718778103590012,\n",
       "  'gpt_38': 0.06800823658704758,\n",
       "  'gpt_39': -2.2897000312805176,\n",
       "  'gpt_40': -0.08370915055274963,\n",
       "  'gpt_41': -0.056884463876485825,\n",
       "  'gpt_42': -0.07234998047351837,\n",
       "  'gpt_43': 0.04363250359892845,\n",
       "  'gpt_44': 0.0804988220334053,\n",
       "  'gpt_45': -0.09209506958723068,\n",
       "  'gpt_46': -0.037879638373851776,\n",
       "  'gpt_47': -0.032662082463502884,\n",
       "  'gpt_48': -0.031272225081920624,\n",
       "  'gpt_49': 0.04804197698831558,\n",
       "  'gpt_50': 0.0191394854336977,\n",
       "  'gpt_51': 0.05872657522559166,\n",
       "  'gpt_52': -0.03001737780869007,\n",
       "  'gpt_53': 0.004164179787039757,\n",
       "  'gpt_54': -0.022919416427612305,\n",
       "  'gpt_55': -0.12567728757858276,\n",
       "  'gpt_56': -0.05833401903510094,\n",
       "  'gpt_57': -0.0431307777762413,\n",
       "  'gpt_58': 0.017473211511969566,\n",
       "  'gpt_59': -0.02944297343492508,\n",
       "  'gpt_60': -0.023770980536937714,\n",
       "  'gpt_61': -0.020901385694742203,\n",
       "  'gpt_62': 0.053970977663993835,\n",
       "  'gpt_63': -0.015334317460656166,\n",
       "  'gpt_64': -0.046447377651929855,\n",
       "  'gpt_65': 0.0003960058093070984,\n",
       "  'gpt_66': 0.008699903264641762,\n",
       "  'gpt_67': 0.05270454287528992,\n",
       "  'gpt_68': -0.003222554922103882,\n",
       "  'gpt_69': -0.04194769263267517,\n",
       "  'gpt_70': 0.0061234887689352036,\n",
       "  'gpt_71': -0.02998185157775879,\n",
       "  'gpt_72': 0.029576145112514496,\n",
       "  'gpt_73': -0.10198327898979187,\n",
       "  'gpt_74': 0.04697464406490326,\n",
       "  'gpt_75': 0.00013883039355278015,\n",
       "  'gpt_76': -0.058693237602710724,\n",
       "  'gpt_77': -0.014266416430473328,\n",
       "  'gpt_78': 0.04499734565615654,\n",
       "  'gpt_79': -0.05871215835213661,\n",
       "  'gpt_80': -0.1428757607936859,\n",
       "  'gpt_81': -0.04616975784301758,\n",
       "  'gpt_82': 0.061610084027051926,\n",
       "  'gpt_83': 0.09435506910085678,\n",
       "  'gpt_84': 0.08627069741487503,\n",
       "  'gpt_85': -0.029744546860456467,\n",
       "  'gpt_86': 0.032040342688560486,\n",
       "  'gpt_87': 0.020455576479434967,\n",
       "  'gpt_88': 0.11032259464263916,\n",
       "  'gpt_89': -0.042807430028915405,\n",
       "  'gpt_90': 0.1265132576227188,\n",
       "  'gpt_91': -0.09426434338092804,\n",
       "  'gpt_92': 0.07273788750171661,\n",
       "  'gpt_93': -0.07754676043987274,\n",
       "  'gpt_94': 0.006422986276447773,\n",
       "  'gpt_95': -0.030616626143455505,\n",
       "  'gpt_96': 0.01325670350342989,\n",
       "  'gpt_97': -0.13424859941005707,\n",
       "  'gpt_98': -0.03535876423120499,\n",
       "  'gpt_99': 0.04593426361680031,\n",
       "  'gpt_100': -0.002795964479446411,\n",
       "  'gpt_101': 0.05204571411013603,\n",
       "  'gpt_102': 0.07261992245912552,\n",
       "  'gpt_103': 0.18980135023593903,\n",
       "  'gpt_104': 0.09217129647731781,\n",
       "  'gpt_105': -0.017408043146133423,\n",
       "  'gpt_106': -0.05769612640142441,\n",
       "  'gpt_107': -0.06125624477863312,\n",
       "  'gpt_108': 0.05437294393777847,\n",
       "  'gpt_109': 0.025595970451831818,\n",
       "  'gpt_110': 0.007738083600997925,\n",
       "  'gpt_111': -0.04943833127617836,\n",
       "  'gpt_112': 0.09900810569524765,\n",
       "  'gpt_113': 0.13915598392486572,\n",
       "  'gpt_114': 0.6967673301696777,\n",
       "  'gpt_115': 0.02718888223171234,\n",
       "  'gpt_116': 0.04320354387164116,\n",
       "  'gpt_117': -0.013626664876937866,\n",
       "  'gpt_118': -0.035851992666721344,\n",
       "  'gpt_119': -1.3428187370300293,\n",
       "  'gpt_120': 0.011498179286718369,\n",
       "  'gpt_121': -0.7272962331771851,\n",
       "  'gpt_122': -0.14639481902122498,\n",
       "  'gpt_123': 0.07061679661273956,\n",
       "  'gpt_124': -0.1137528270483017,\n",
       "  'gpt_125': 0.006790105253458023,\n",
       "  'gpt_126': 0.03430722653865814,\n",
       "  'gpt_127': 0.04346571862697601,\n",
       "  'gpt_128': -0.11254775524139404,\n",
       "  'gpt_129': 0.1133074089884758,\n",
       "  'gpt_130': 0.09065116941928864,\n",
       "  'gpt_131': -0.32491153478622437,\n",
       "  'gpt_132': -0.018899161368608475,\n",
       "  'gpt_133': 0.026759743690490723,\n",
       "  'gpt_134': -0.05351710319519043,\n",
       "  'gpt_135': 0.05092022567987442,\n",
       "  'gpt_136': 0.3050772547721863,\n",
       "  'gpt_137': 0.029699284583330154,\n",
       "  'gpt_138': -0.028475724160671234,\n",
       "  'gpt_139': 0.02695479243993759,\n",
       "  'gpt_140': -0.02082056924700737,\n",
       "  'gpt_141': 0.37974393367767334,\n",
       "  'gpt_142': 0.027228496968746185,\n",
       "  'gpt_143': -0.1476978361606598,\n",
       "  'gpt_144': -0.005291569046676159,\n",
       "  'gpt_145': -0.035060249269008636,\n",
       "  'gpt_146': -0.018356479704380035,\n",
       "  'gpt_147': -0.05460820347070694,\n",
       "  'gpt_148': -0.01564151421189308,\n",
       "  'gpt_149': -0.0071098897606134415,\n",
       "  'gpt_150': -0.010823670774698257,\n",
       "  'gpt_151': -0.003938049077987671,\n",
       "  'gpt_152': 0.03476104885339737,\n",
       "  'gpt_153': 0.0029630158096551895,\n",
       "  'gpt_154': -0.02616024948656559,\n",
       "  'gpt_155': 0.0032416079193353653,\n",
       "  'gpt_156': 0.04505302011966705,\n",
       "  'gpt_157': -0.006844429299235344,\n",
       "  'gpt_158': 0.10844076424837112,\n",
       "  'gpt_159': -0.017024800181388855,\n",
       "  'gpt_160': 0.06821566820144653,\n",
       "  'gpt_161': 0.02581367827951908,\n",
       "  'gpt_162': 0.005417142063379288,\n",
       "  'gpt_163': -0.06204141303896904,\n",
       "  'gpt_164': -0.013939651660621166,\n",
       "  'gpt_165': -0.029074983671307564,\n",
       "  'gpt_166': -0.009241567924618721,\n",
       "  'gpt_167': 0.011087821796536446,\n",
       "  'gpt_168': -0.03303147107362747,\n",
       "  'gpt_169': 0.009206440299749374,\n",
       "  'gpt_170': 0.11485403031110764,\n",
       "  'gpt_171': 0.026943862438201904,\n",
       "  'gpt_172': -0.013965487480163574,\n",
       "  'gpt_173': 0.012512905523180962,\n",
       "  'gpt_174': -0.0229409858584404,\n",
       "  'gpt_175': 0.03407442197203636,\n",
       "  'gpt_176': 0.011225888505578041,\n",
       "  'gpt_177': -0.020225882530212402,\n",
       "  'gpt_178': 0.026149272918701172,\n",
       "  'gpt_179': -0.01847061887383461,\n",
       "  'gpt_180': 0.051783982664346695,\n",
       "  'gpt_181': -0.06428679823875427,\n",
       "  'gpt_182': 0.1040821224451065,\n",
       "  'gpt_183': -0.0621819905936718,\n",
       "  'gpt_184': -0.013513654470443726,\n",
       "  'gpt_185': -0.22206808626651764,\n",
       "  'gpt_186': 0.01840006373822689,\n",
       "  'gpt_187': 0.08244089782238007,\n",
       "  'gpt_188': -0.054667357355356216,\n",
       "  'gpt_189': 0.07109616696834564,\n",
       "  'gpt_190': 0.03196817263960838,\n",
       "  'gpt_191': -0.04328414797782898,\n",
       "  'gpt_192': 0.0540601871907711,\n",
       "  'gpt_193': -0.018319997936487198,\n",
       "  'gpt_194': 0.14387130737304688,\n",
       "  'gpt_195': 0.04201795905828476,\n",
       "  'gpt_196': -0.026688531041145325,\n",
       "  'gpt_197': -0.02872512862086296,\n",
       "  'gpt_198': 0.009464280679821968,\n",
       "  'gpt_199': 0.09508278965950012,\n",
       "  'gpt_200': 0.06276877224445343,\n",
       "  'gpt_201': -1.3799424171447754,\n",
       "  'gpt_202': -0.024678915739059448,\n",
       "  'gpt_203': 0.029436729848384857,\n",
       "  'gpt_204': -0.8536491990089417,\n",
       "  'gpt_205': 0.08974562585353851,\n",
       "  'gpt_206': -0.04373115673661232,\n",
       "  'gpt_207': 0.05121384933590889,\n",
       "  'gpt_208': 0.06296125799417496,\n",
       "  'gpt_209': -0.018432635813951492,\n",
       "  'gpt_210': -0.07874268293380737,\n",
       "  'gpt_211': 0.014493659138679504,\n",
       "  'gpt_212': 0.07171043008565903,\n",
       "  'gpt_213': 0.040596190840005875,\n",
       "  'gpt_214': 0.044908374547958374,\n",
       "  'gpt_215': 0.08357854187488556,\n",
       "  'gpt_216': 0.0036173015832901,\n",
       "  'gpt_217': 0.014011096209287643,\n",
       "  'gpt_218': -0.08888569474220276,\n",
       "  'gpt_219': 0.029077798128128052,\n",
       "  'gpt_220': -0.06860770285129547,\n",
       "  'gpt_221': -0.0015041045844554901,\n",
       "  'gpt_222': 0.022355999797582626,\n",
       "  'gpt_223': -0.02850579470396042,\n",
       "  'gpt_224': 0.022791387513279915,\n",
       "  'gpt_225': 0.07074042409658432,\n",
       "  'gpt_226': 0.0479418970644474,\n",
       "  'gpt_227': 0.08351362496614456,\n",
       "  'gpt_228': 0.012249925173819065,\n",
       "  'gpt_229': -0.02511925809085369,\n",
       "  'gpt_230': 0.07899262756109238,\n",
       "  'gpt_231': -0.0038618668913841248,\n",
       "  'gpt_232': -0.015513911843299866,\n",
       "  'gpt_233': 0.05362799018621445,\n",
       "  'gpt_234': 0.08777754008769989,\n",
       "  'gpt_235': -0.0061799101531505585,\n",
       "  'gpt_236': -0.6668334007263184,\n",
       "  'gpt_237': 0.012252943590283394,\n",
       "  'gpt_238': -0.11118701100349426,\n",
       "  'gpt_239': 0.0024869441986083984,\n",
       "  'gpt_240': 0.09809066355228424,\n",
       "  'gpt_241': 0.06473305821418762,\n",
       "  'gpt_242': -0.16124939918518066,\n",
       "  'gpt_243': -4.565220355987549,\n",
       "  'gpt_244': 0.2493750900030136,\n",
       "  'gpt_245': 0.05794663727283478,\n",
       "  'gpt_246': 0.05467163026332855,\n",
       "  'gpt_247': 0.10687169432640076,\n",
       "  'gpt_248': 0.021743405610322952,\n",
       "  'gpt_249': 1.013824224472046,\n",
       "  'gpt_250': 0.19661742448806763,\n",
       "  'gpt_251': 0.05140744894742966,\n",
       "  'gpt_252': -0.10185093432664871,\n",
       "  'gpt_253': 0.0019897758029401302,\n",
       "  'gpt_254': 0.05824372544884682,\n",
       "  'gpt_255': 0.038512177765369415}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ds[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_new = pd.DataFrame(new_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_orig</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "      <th>task</th>\n",
       "      <th>gpt_0</th>\n",
       "      <th>gpt_1</th>\n",
       "      <th>gpt_2</th>\n",
       "      <th>gpt_3</th>\n",
       "      <th>gpt_4</th>\n",
       "      <th>gpt_5</th>\n",
       "      <th>gpt_6</th>\n",
       "      <th>gpt_7</th>\n",
       "      <th>gpt_8</th>\n",
       "      <th>gpt_9</th>\n",
       "      <th>gpt_10</th>\n",
       "      <th>gpt_11</th>\n",
       "      <th>gpt_12</th>\n",
       "      <th>gpt_13</th>\n",
       "      <th>gpt_14</th>\n",
       "      <th>gpt_15</th>\n",
       "      <th>gpt_16</th>\n",
       "      <th>gpt_17</th>\n",
       "      <th>gpt_18</th>\n",
       "      <th>gpt_19</th>\n",
       "      <th>gpt_20</th>\n",
       "      <th>gpt_21</th>\n",
       "      <th>gpt_22</th>\n",
       "      <th>gpt_23</th>\n",
       "      <th>gpt_24</th>\n",
       "      <th>gpt_25</th>\n",
       "      <th>gpt_26</th>\n",
       "      <th>gpt_27</th>\n",
       "      <th>gpt_28</th>\n",
       "      <th>gpt_29</th>\n",
       "      <th>gpt_30</th>\n",
       "      <th>gpt_31</th>\n",
       "      <th>gpt_32</th>\n",
       "      <th>gpt_33</th>\n",
       "      <th>gpt_34</th>\n",
       "      <th>gpt_35</th>\n",
       "      <th>...</th>\n",
       "      <th>gpt_216</th>\n",
       "      <th>gpt_217</th>\n",
       "      <th>gpt_218</th>\n",
       "      <th>gpt_219</th>\n",
       "      <th>gpt_220</th>\n",
       "      <th>gpt_221</th>\n",
       "      <th>gpt_222</th>\n",
       "      <th>gpt_223</th>\n",
       "      <th>gpt_224</th>\n",
       "      <th>gpt_225</th>\n",
       "      <th>gpt_226</th>\n",
       "      <th>gpt_227</th>\n",
       "      <th>gpt_228</th>\n",
       "      <th>gpt_229</th>\n",
       "      <th>gpt_230</th>\n",
       "      <th>gpt_231</th>\n",
       "      <th>gpt_232</th>\n",
       "      <th>gpt_233</th>\n",
       "      <th>gpt_234</th>\n",
       "      <th>gpt_235</th>\n",
       "      <th>gpt_236</th>\n",
       "      <th>gpt_237</th>\n",
       "      <th>gpt_238</th>\n",
       "      <th>gpt_239</th>\n",
       "      <th>gpt_240</th>\n",
       "      <th>gpt_241</th>\n",
       "      <th>gpt_242</th>\n",
       "      <th>gpt_243</th>\n",
       "      <th>gpt_244</th>\n",
       "      <th>gpt_245</th>\n",
       "      <th>gpt_246</th>\n",
       "      <th>gpt_247</th>\n",
       "      <th>gpt_248</th>\n",
       "      <th>gpt_249</th>\n",
       "      <th>gpt_250</th>\n",
       "      <th>gpt_251</th>\n",
       "      <th>gpt_252</th>\n",
       "      <th>gpt_253</th>\n",
       "      <th>gpt_254</th>\n",
       "      <th>gpt_255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACGGCAGCTCGCCATCATCG</td>\n",
       "      <td>ACGGCAGCTCGCCATCATCGGGG</td>\n",
       "      <td>0.3</td>\n",
       "      <td>BE39:MELJUSO:zscore</td>\n",
       "      <td>0.125914</td>\n",
       "      <td>0.051607</td>\n",
       "      <td>-0.047553</td>\n",
       "      <td>-0.022943</td>\n",
       "      <td>0.016563</td>\n",
       "      <td>-0.041671</td>\n",
       "      <td>0.023357</td>\n",
       "      <td>0.044482</td>\n",
       "      <td>0.111030</td>\n",
       "      <td>0.044558</td>\n",
       "      <td>-0.067879</td>\n",
       "      <td>0.071323</td>\n",
       "      <td>-0.035050</td>\n",
       "      <td>-0.033921</td>\n",
       "      <td>-0.001965</td>\n",
       "      <td>-0.020947</td>\n",
       "      <td>0.054193</td>\n",
       "      <td>-0.049541</td>\n",
       "      <td>-0.014107</td>\n",
       "      <td>-0.024532</td>\n",
       "      <td>0.062198</td>\n",
       "      <td>-0.075282</td>\n",
       "      <td>0.059594</td>\n",
       "      <td>0.058393</td>\n",
       "      <td>0.079202</td>\n",
       "      <td>-0.022146</td>\n",
       "      <td>0.040812</td>\n",
       "      <td>-0.100016</td>\n",
       "      <td>-0.097090</td>\n",
       "      <td>0.029079</td>\n",
       "      <td>0.008716</td>\n",
       "      <td>0.029332</td>\n",
       "      <td>0.061030</td>\n",
       "      <td>0.089095</td>\n",
       "      <td>0.020949</td>\n",
       "      <td>-0.132523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.014011</td>\n",
       "      <td>-0.088886</td>\n",
       "      <td>0.029078</td>\n",
       "      <td>-0.068608</td>\n",
       "      <td>-0.001504</td>\n",
       "      <td>0.022356</td>\n",
       "      <td>-0.028506</td>\n",
       "      <td>0.022791</td>\n",
       "      <td>0.070740</td>\n",
       "      <td>0.047942</td>\n",
       "      <td>0.083514</td>\n",
       "      <td>0.012250</td>\n",
       "      <td>-0.025119</td>\n",
       "      <td>0.078993</td>\n",
       "      <td>-0.003862</td>\n",
       "      <td>-0.015514</td>\n",
       "      <td>0.053628</td>\n",
       "      <td>0.087778</td>\n",
       "      <td>-0.006180</td>\n",
       "      <td>-0.666833</td>\n",
       "      <td>0.012253</td>\n",
       "      <td>-0.111187</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>0.098091</td>\n",
       "      <td>0.064733</td>\n",
       "      <td>-0.161249</td>\n",
       "      <td>-4.565220</td>\n",
       "      <td>0.249375</td>\n",
       "      <td>0.057947</td>\n",
       "      <td>0.054672</td>\n",
       "      <td>0.106872</td>\n",
       "      <td>0.021743</td>\n",
       "      <td>1.013824</td>\n",
       "      <td>0.196617</td>\n",
       "      <td>0.051407</td>\n",
       "      <td>-0.101851</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>0.058244</td>\n",
       "      <td>0.038512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTCTCAGATATGGTCTTAAA</td>\n",
       "      <td>TTCTCAGATATGGTCTTAAAAGG</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>BE39:MELJUSO:zscore</td>\n",
       "      <td>0.046595</td>\n",
       "      <td>-0.024450</td>\n",
       "      <td>-0.058685</td>\n",
       "      <td>0.006605</td>\n",
       "      <td>-0.011588</td>\n",
       "      <td>0.008578</td>\n",
       "      <td>0.044201</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.022437</td>\n",
       "      <td>-0.033208</td>\n",
       "      <td>0.030673</td>\n",
       "      <td>-0.002213</td>\n",
       "      <td>0.055722</td>\n",
       "      <td>-0.005216</td>\n",
       "      <td>0.015321</td>\n",
       "      <td>0.012713</td>\n",
       "      <td>0.017152</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.044287</td>\n",
       "      <td>0.036159</td>\n",
       "      <td>-0.037070</td>\n",
       "      <td>0.042819</td>\n",
       "      <td>0.022769</td>\n",
       "      <td>-0.051338</td>\n",
       "      <td>-0.019025</td>\n",
       "      <td>0.019725</td>\n",
       "      <td>-0.008076</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>-0.003903</td>\n",
       "      <td>0.028443</td>\n",
       "      <td>0.013148</td>\n",
       "      <td>-0.032114</td>\n",
       "      <td>0.043635</td>\n",
       "      <td>0.044110</td>\n",
       "      <td>-0.033816</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005065</td>\n",
       "      <td>0.031149</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.049138</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.051153</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>-0.002005</td>\n",
       "      <td>0.022871</td>\n",
       "      <td>0.068247</td>\n",
       "      <td>0.017211</td>\n",
       "      <td>0.082055</td>\n",
       "      <td>0.010086</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.007221</td>\n",
       "      <td>0.004519</td>\n",
       "      <td>0.044025</td>\n",
       "      <td>0.025114</td>\n",
       "      <td>0.007125</td>\n",
       "      <td>0.517080</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>-0.048028</td>\n",
       "      <td>0.015808</td>\n",
       "      <td>0.011982</td>\n",
       "      <td>0.051470</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>-3.878134</td>\n",
       "      <td>-0.027961</td>\n",
       "      <td>0.009970</td>\n",
       "      <td>0.018673</td>\n",
       "      <td>0.030737</td>\n",
       "      <td>-0.002636</td>\n",
       "      <td>-1.303357</td>\n",
       "      <td>-0.023476</td>\n",
       "      <td>0.032480</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>0.009350</td>\n",
       "      <td>0.019897</td>\n",
       "      <td>0.029615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GCTGCAGTTGACACACTGGG</td>\n",
       "      <td>GCTGCAGTTGACACACTGGGTGG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BE39:MELJUSO:zscore</td>\n",
       "      <td>0.019764</td>\n",
       "      <td>-0.011866</td>\n",
       "      <td>-0.008757</td>\n",
       "      <td>0.029762</td>\n",
       "      <td>0.019669</td>\n",
       "      <td>0.051780</td>\n",
       "      <td>0.079187</td>\n",
       "      <td>0.030046</td>\n",
       "      <td>-0.025103</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>-0.062993</td>\n",
       "      <td>0.053278</td>\n",
       "      <td>0.019820</td>\n",
       "      <td>0.023191</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>-0.016876</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.052163</td>\n",
       "      <td>-0.021933</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.004648</td>\n",
       "      <td>-0.003641</td>\n",
       "      <td>0.035660</td>\n",
       "      <td>-0.008423</td>\n",
       "      <td>-0.058473</td>\n",
       "      <td>0.030080</td>\n",
       "      <td>0.027637</td>\n",
       "      <td>0.040358</td>\n",
       "      <td>0.014709</td>\n",
       "      <td>0.034148</td>\n",
       "      <td>-0.032597</td>\n",
       "      <td>-0.025167</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.025336</td>\n",
       "      <td>-0.030684</td>\n",
       "      <td>0.007105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007354</td>\n",
       "      <td>0.034133</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.039005</td>\n",
       "      <td>-0.007096</td>\n",
       "      <td>0.047441</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.081519</td>\n",
       "      <td>-0.001905</td>\n",
       "      <td>0.094714</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.062526</td>\n",
       "      <td>0.029322</td>\n",
       "      <td>0.049515</td>\n",
       "      <td>0.013537</td>\n",
       "      <td>0.056761</td>\n",
       "      <td>-0.007342</td>\n",
       "      <td>0.050315</td>\n",
       "      <td>-0.034251</td>\n",
       "      <td>0.037931</td>\n",
       "      <td>0.765546</td>\n",
       "      <td>0.050311</td>\n",
       "      <td>0.009072</td>\n",
       "      <td>0.066612</td>\n",
       "      <td>-0.002333</td>\n",
       "      <td>0.040317</td>\n",
       "      <td>0.050887</td>\n",
       "      <td>-4.250634</td>\n",
       "      <td>-0.145295</td>\n",
       "      <td>0.064880</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.058887</td>\n",
       "      <td>0.029008</td>\n",
       "      <td>0.676880</td>\n",
       "      <td>-0.113978</td>\n",
       "      <td>0.053165</td>\n",
       "      <td>0.019509</td>\n",
       "      <td>0.052915</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.028595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GTGGTGTTCCGGCTTCAGGT</td>\n",
       "      <td>GTGGTGTTCCGGCTTCAGGTGGG</td>\n",
       "      <td>0.6</td>\n",
       "      <td>BE39:MELJUSO:zscore</td>\n",
       "      <td>0.059406</td>\n",
       "      <td>-0.026775</td>\n",
       "      <td>-0.026016</td>\n",
       "      <td>0.047232</td>\n",
       "      <td>0.036030</td>\n",
       "      <td>0.012072</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>-0.021350</td>\n",
       "      <td>-0.028008</td>\n",
       "      <td>0.045886</td>\n",
       "      <td>0.032879</td>\n",
       "      <td>-0.048041</td>\n",
       "      <td>0.021854</td>\n",
       "      <td>0.004847</td>\n",
       "      <td>-0.058433</td>\n",
       "      <td>-0.061785</td>\n",
       "      <td>-0.013992</td>\n",
       "      <td>-0.029875</td>\n",
       "      <td>-0.026898</td>\n",
       "      <td>-0.015040</td>\n",
       "      <td>0.006215</td>\n",
       "      <td>-0.066658</td>\n",
       "      <td>0.066843</td>\n",
       "      <td>-0.030151</td>\n",
       "      <td>0.079054</td>\n",
       "      <td>0.038404</td>\n",
       "      <td>-0.016863</td>\n",
       "      <td>0.043335</td>\n",
       "      <td>0.053637</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>-0.001084</td>\n",
       "      <td>0.081036</td>\n",
       "      <td>-0.013629</td>\n",
       "      <td>-0.013296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009974</td>\n",
       "      <td>0.046436</td>\n",
       "      <td>-0.009647</td>\n",
       "      <td>0.061094</td>\n",
       "      <td>0.006363</td>\n",
       "      <td>0.091702</td>\n",
       "      <td>-0.016922</td>\n",
       "      <td>0.050879</td>\n",
       "      <td>0.019253</td>\n",
       "      <td>0.226620</td>\n",
       "      <td>-0.014389</td>\n",
       "      <td>0.080640</td>\n",
       "      <td>0.028546</td>\n",
       "      <td>0.045448</td>\n",
       "      <td>0.016225</td>\n",
       "      <td>0.069756</td>\n",
       "      <td>-0.004355</td>\n",
       "      <td>0.061293</td>\n",
       "      <td>-0.020023</td>\n",
       "      <td>0.036907</td>\n",
       "      <td>0.351479</td>\n",
       "      <td>0.068779</td>\n",
       "      <td>-0.010102</td>\n",
       "      <td>0.049406</td>\n",
       "      <td>0.030639</td>\n",
       "      <td>0.103413</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>-4.408957</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.066362</td>\n",
       "      <td>0.039539</td>\n",
       "      <td>0.085634</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>0.225784</td>\n",
       "      <td>-0.060546</td>\n",
       "      <td>0.058458</td>\n",
       "      <td>-0.023439</td>\n",
       "      <td>0.036487</td>\n",
       "      <td>0.044296</td>\n",
       "      <td>0.071402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GGTGTCCCTTTGAAGGTGCT</td>\n",
       "      <td>GGTGTCCCTTTGAAGGTGCTGGG</td>\n",
       "      <td>0.6</td>\n",
       "      <td>BE39:MELJUSO:zscore</td>\n",
       "      <td>0.042620</td>\n",
       "      <td>-0.107365</td>\n",
       "      <td>0.065568</td>\n",
       "      <td>0.052436</td>\n",
       "      <td>0.030147</td>\n",
       "      <td>0.089224</td>\n",
       "      <td>0.047095</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>-0.003510</td>\n",
       "      <td>-0.059568</td>\n",
       "      <td>-0.055953</td>\n",
       "      <td>0.116043</td>\n",
       "      <td>0.007154</td>\n",
       "      <td>0.007261</td>\n",
       "      <td>0.015405</td>\n",
       "      <td>0.049635</td>\n",
       "      <td>0.008412</td>\n",
       "      <td>-0.027478</td>\n",
       "      <td>0.037917</td>\n",
       "      <td>-0.046747</td>\n",
       "      <td>-0.136207</td>\n",
       "      <td>0.056950</td>\n",
       "      <td>-0.007439</td>\n",
       "      <td>-0.046437</td>\n",
       "      <td>-0.015417</td>\n",
       "      <td>-0.006238</td>\n",
       "      <td>0.013901</td>\n",
       "      <td>0.013517</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.027176</td>\n",
       "      <td>0.034579</td>\n",
       "      <td>-0.027821</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.051305</td>\n",
       "      <td>-0.030875</td>\n",
       "      <td>-0.064363</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009396</td>\n",
       "      <td>0.041522</td>\n",
       "      <td>-0.001220</td>\n",
       "      <td>0.060058</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>0.091724</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.004569</td>\n",
       "      <td>0.170114</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>0.042690</td>\n",
       "      <td>-0.023456</td>\n",
       "      <td>0.016970</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>0.035752</td>\n",
       "      <td>-0.030229</td>\n",
       "      <td>0.064989</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.017434</td>\n",
       "      <td>1.218952</td>\n",
       "      <td>0.043436</td>\n",
       "      <td>-0.034053</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>-0.001985</td>\n",
       "      <td>0.067431</td>\n",
       "      <td>0.051375</td>\n",
       "      <td>-4.528712</td>\n",
       "      <td>-0.055255</td>\n",
       "      <td>0.027935</td>\n",
       "      <td>0.022609</td>\n",
       "      <td>0.034118</td>\n",
       "      <td>-0.052611</td>\n",
       "      <td>-0.157527</td>\n",
       "      <td>-0.047898</td>\n",
       "      <td>0.037487</td>\n",
       "      <td>0.040009</td>\n",
       "      <td>0.021785</td>\n",
       "      <td>-0.018878</td>\n",
       "      <td>0.062287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence_orig                 sequence  ...   gpt_254   gpt_255\n",
       "0  ACGGCAGCTCGCCATCATCG  ACGGCAGCTCGCCATCATCGGGG  ...  0.058244  0.038512\n",
       "1  TTCTCAGATATGGTCTTAAA  TTCTCAGATATGGTCTTAAAAGG  ...  0.019897  0.029615\n",
       "2  GCTGCAGTTGACACACTGGG  GCTGCAGTTGACACACTGGGTGG  ...  0.011747  0.028595\n",
       "3  GTGGTGTTCCGGCTTCAGGT  GTGGTGTTCCGGCTTCAGGTGGG  ...  0.044296  0.071402\n",
       "4  GGTGTCCCTTTGAAGGTGCT  GGTGTCCCTTTGAAGGTGCTGGG  ... -0.018878  0.062287\n",
       "\n",
       "[5 rows x 260 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_parquet(\"data.tmp/ds_zscore_gpt12M_pretrain_only_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/collections/sapienzanlp/ita-bench-italian-benchmarks-for-llms-66337ca59e6df7d7d4933896"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradientlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
